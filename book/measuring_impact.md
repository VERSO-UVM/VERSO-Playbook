
# Measuring Impact

Measuring impact is more than an exercise in reporting numbers—it is about telling the story of why VERSO matters. From the beginning, we understood that building an Open Source Program Office inside a university was an experiment, and like any experiment, it required evidence to validate its success.

However, the path to measurement was far from straightforward. What we assumed would be easy to track turned out to be irrelevant, incomplete, or misleading. In some cases, the data simply did not exist. Even our initial survey, which revealed that most respondents did not know what open source was, highlighted a fundamental challenge: we were trying to measure progress in a landscape where the baseline was unclear.

One of the earliest examples of this difficulty came from trying to gather statistics from the UVM‑hosted GitLab instance about the number of public repositories. A first‑pass query showed 43 repositories with open‑source licenses—yet one repository, upon inspection, consisted solely of a README stating: *“I had no idea we had a GitLab.”* The situation on GitHub was even more complicated: while we found nearly 14,000 public repositories referencing “UVM,” attributing them to actual UVM faculty, staff, or students was nearly impossible because most people used personal GitHub accounts. Attempts to catalogue those accounts raised important questions around privacy, autonomy, and the role of a university office in indexing individuals’ digital identities.

Beyond this, broader ecosystem metrics were opaque. UVM’s GitLab instance had low adoption, GitHub attribution was unreliable, and large open‑source projects involving UVM were often co‑owned by collaborators at many institutions. In these cases, what did “UVM ownership” even mean?

Ultimately, we recognized that measuring the entire “open‑source ecosystem” was neither concrete nor functional. Instead, we pivoted toward creating our own projects—initiatives where we could define measurable goals, control data quality, and document clear outcomes.

---

# Key Metrics

From the earliest days of VERSO, we understood that enthusiasm alone could not sustain an academic Open Source Program Office. To justify long‑term investment—financial, organizational, and cultural—we needed metrics that demonstrated real, defensible impact. Over time, our approach evolved into a multidimensional framework reflecting not only program activity but also ecosystem growth, cultural transformation, and lasting institutional value.

## 1. Student Engagement & Workforce Development

Students are the engine of VERSO and ORCA. Their participation and professional growth offer some of the most direct evidence of our success.

**Core metrics include:**

- **Total ORCA student participants per year**
- **Cumulative hours students contribute to real open work**
- **Retention and progression**, such as students returning for multiple semesters or advancing to lead roles
- **Career outcomes**, including internships, research positions, or employment related to open‑source skills
- **Skill benchmarks**, such as the first merged PR, first release, or first public presentation

These metrics illuminate how VERSO prepares students for open‑source practice and supports a workforce trained in real production‑quality tools and methods.

---

## 2. Project Portfolio & Research Output

As VERSO’s work expanded, the number and diversity of open‑source projects became a tangible measure of impact. We began tracking:

- **Total active VERSO and ORCA projects**, updated each semester
- **Project categories**, including research software, community tools, mapping systems, analytics platforms, and documentation projects
- **Project maturity metrics**, such as completed milestones, release cycles, or adoption by users beyond UVM
- **Technical contributions**, including issues resolved, documentation improved, pull requests merged, and new features created

These indicators help quantify VERSO’s ability to produce high‑quality, open, and reusable software aligned with academic research needs.

---

## 3. Partnerships & Ecosystem Connectivity

A healthy open ecosystem can only thrive through collaboration. Over time, VERSO built relationships across UVM and beyond.

**Metrics include:**

- **Number of UVM research collaborators**, such as labs, institutes, and centers
- **External partners**, including nonprofits, state agencies, local governments, and other universities
- **Repeat or long‑term partners**, measuring trust, satisfaction, and ongoing engagement
- **Collaborative outputs**, such as co‑developed tools, datasets, or publications

These metrics reflect how well VERSO strengthens UVM’s connections to regional, national, and international open‑source communities.

---

## 4. Open Data Adoption & Dataverse Utilization

With the launch of the UVM Dataverse, VERSO gained new visibility into open‑data practices across campus.

**Key metrics include:**

- **Datasets published** by faculty, students, and research units  
- **Download and access counts**, which signal community interest and impact  
- **Dataset diversity**, identifying which disciplines are engaging in open‑data publishing  
- **Citation and reuse metrics**, where available, showing downstream influence  

These measures help track the spread of open‑data culture and provide evidence of real‑world impact.

---

## 5. Institutional Presence & Cultural Change

Building an open culture is long‑term work, and many of its indicators do not appear immediately. As awareness grew, however, VERSO began monitoring:

- **New GitHub/GitLab organizations** created by labs or research groups  
- **Growth of openly licensed repositories**  
- **Requests for consultations**, training sessions, curriculum support, or infrastructure guidance  
- **Faculty and staff participation** in open‑work initiatives, workshops, and project collaborations  

These indicators provide insight into how open‑source thinking is taking root across the university.

---

## 6. Events, Training & Community Engagement

As VERSO expanded its educational programs, event‑based metrics became valuable for understanding reach and community dynamics.

**Metrics include:**

- **Workshops, lectures, and events hosted**  
- **Attendance levels and return rates**  
- **Number and diversity of presenters**  
- **Sponsorships and external support**, demonstrating validation and institutional buy‑in  
- **Feedback and qualitative evaluations**, reflecting participant experience  

These metrics highlight VERSO’s role in cultivating a vibrant, informed, and engaged open‑source community.

---

# Beyond Numbers

While metrics provide snapshots of progress, they cannot capture transformation on their own. The number of workshops held or repositories created illustrates activity but not meaning. To fully understand VERSO’s impact, we must also embrace stories, testimonials, unexpected outcomes, and culture shifts—forms of impact that numbers alone cannot quantify.

Metrics matter. But ultimately, they are only one part of a broader narrative about building a sustainable, equitable, and open ecosystem at UVM.
``
